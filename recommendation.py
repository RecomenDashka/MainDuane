import os
import json
import logging
import google.generativeai as genai
from typing import List, Dict, Any, Optional
import requests
import re
from database import MovieDatabase
import asyncio
import time
import random
from urllib.parse import urlparse
import httpx
import ssl

# Configure logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)


class RecommendationEngine:
    def __init__(self, api_key: str, tmdb_api_key: str, db: MovieDatabase):
        """
        Initialize the recommendation engine.

        Args:
            api_key: Google Gemini API key
            tmdb_api_key: TMDB API key
            db: MovieDatabase instance
        """
        self.api_key = api_key
        self.tmdb_api_key = tmdb_api_key
        self.db = db
        self.tmdb_base_url = "https://api.themoviedb.org/3"

        # Configure Google Generative AI
        genai.configure(api_key=api_key)

        # For proxy fallback
        self.use_proxy = False
        self.proxies = []
        self.current_proxy = None

        # Get available models and select appropriate model
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤ —Å–ø–∏—Å–æ–∫
            self.models = list(genai.list_models())
            logger.info(f"Found {len(self.models)} available models")

            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—ã–±–æ—Ä–∞ - –æ—Ç –ø—Ä–æ—Å—Ç—ã—Ö –∫ —Å–ª–æ–∂–Ω—ã–º
            model_preference = [
                "gemini-1.5-flash-8b",  # –°–∞–º–∞—è –ª–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å
                "gemini-1.5-flash",  # –õ–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å
                "gemini-1.0-pro-vision",
                "gemini-1.5-pro",  # –ú–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å
            ]

            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –º–æ–¥–µ–ª—å –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–º—É —Å–ø–∏—Å–∫—É
            selected_model = None
            for preferred_model in model_preference:
                for model in self.models:
                    if preferred_model in model.name and hasattr(model,
                                                                 'supported_generation_methods') and model.supported_generation_methods and "generateContent" in model.supported_generation_methods:
                        selected_model = model.name
                        logger.info(f"Selected model from priority list: {selected_model}")
                        break
                if selected_model:
                    break

            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –º–æ–¥–µ–ª—å –∏–∑ —Å–ø–∏—Å–∫–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤, –≤–æ–∑—å–º–µ–º –ø–µ—Ä–≤—É—é flash –º–æ–¥–µ–ª—å –∏–ª–∏ –ª—é–±—É—é –¥—Ä—É–≥—É—é
            if not selected_model:
                flash_models = [m for m in self.models if "flash" in m.name.lower()
                                and hasattr(m, 'supported_generation_methods')
                                and m.supported_generation_methods
                                and "generateContent" in m.supported_generation_methods]

                if flash_models:
                    selected_model = flash_models[0].name
                    logger.info(f"Using flash model: {selected_model}")
                else:
                    # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –ª—é–±–∞—è –º–æ–¥–µ–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π generateContent
                    content_models = [m for m in self.models
                                      if hasattr(m, 'supported_generation_methods')
                                      and m.supported_generation_methods
                                      and "generateContent" in m.supported_generation_methods]

                    if content_models:
                        selected_model = content_models[0].name
                        logger.info(f"Using available model: {selected_model}")
                    else:
                        # –ï—Å–ª–∏ —Å–æ–≤—Å–µ–º –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º–æ–¥–µ–ª—å
                        selected_model = "gemini-1.5-flash"
                        logger.warning(f"No suitable models found, defaulting to: {selected_model}")

            self.model = genai.GenerativeModel(selected_model)
            logger.info(f"Successfully initialized model: {selected_model}")

        except Exception as e:
            logger.error(f"Error selecting model: {str(e)}")
            # Fallback to a lightweight model
            self.model = genai.GenerativeModel("gemini-1.5-flash")
            logger.info("Using default model: gemini-1.5-flash due to error")

    async def _get_free_proxies(self) -> List[str]:
        """Get a list of free proxies to try."""
        try:
            # Try several free proxy sources
            proxy_sources = [
                "https://raw.githubusercontent.com/TheSpeedX/PROXY-List/master/http.txt",
                "https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/http.txt",
                "https://raw.githubusercontent.com/ShiftyTR/Proxy-List/master/http.txt"
            ]

            all_proxies = []
            async with httpx.AsyncClient(timeout=5.0) as client:
                for source in proxy_sources:
                    try:
                        response = await client.get(source)
                        if response.status_code == 200:
                            proxies = [f"http://{line.strip()}" for line in response.text.splitlines() if line.strip()]
                            all_proxies.extend(proxies)
                            logger.info(f"Found {len(proxies)} proxies from {source}")
                    except Exception as e:
                        logger.warning(f"Failed to get proxies from {source}: {e}")

            # Shuffle to distribute load
            random.shuffle(all_proxies)
            return all_proxies[:25]  # Limit to 25 to avoid excessive retries
        except Exception as e:
            logger.error(f"Error getting free proxies: {e}")
            return []

    async def _test_proxy(self, proxy: str) -> bool:
        """Test if a proxy works with Google API."""
        try:
            parsed = urlparse(proxy)
            if not parsed.scheme or not parsed.netloc:
                return False

            # Try a simple HEAD request to Google
            async with httpx.AsyncClient(proxies={"http://": proxy, "https://": proxy}, timeout=5.0) as client:
                response = await client.head("https://generativelanguage.googleapis.com/", timeout=3.0)
                return response.status_code < 400
        except Exception:
            return False

    async def _setup_proxy_if_needed(self):
        """Set up proxy if we haven't already and need one."""
        if self.use_proxy and not self.proxies:
            logger.info("Setting up proxy fallback due to location restrictions")
            self.proxies = await self._get_free_proxies()
            if not self.proxies:
                logger.warning("No working proxies found")

    async def _get_working_proxy(self) -> Optional[str]:
        """Get a working proxy or None if none available."""
        await self._setup_proxy_if_needed()

        if not self.proxies:
            return None

        # Try proxies until we find a working one
        max_attempts = min(5, len(self.proxies))
        for _ in range(max_attempts):
            if not self.proxies:
                return None

            proxy = self.proxies.pop(0)
            if await self._test_proxy(proxy):
                logger.info(f"Found working proxy: {proxy}")
                return proxy

        return None

    async def generate_recommendations(self, user_query: str, user_id: Optional[int] = None) -> Dict[str, Any]:
        """
        Generate movie recommendations based on user query using Google Gemini.

        Args:
            user_query: User's request for recommendations
            user_id: Optional Telegram user ID for personalization

        Returns:
            Dictionary containing recommendation results
        """
        try:
            # Get list of already rated movies to exclude them
            excluded_movies = []
            if user_id:
                user_ratings = self.db.get_user_ratings(user_id)
                excluded_movies = [rating['title'] for rating in user_ratings]

            # –ù–û–í–û–ï: –û–±–æ–≥–∞—â–∞–µ–º –∑–∞–ø—Ä–æ—Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ TMDB
            logger.info("Enriching query with TMDB data...")
            enriched_user_query = await self._enrich_query_with_tmdb_data(user_query)

            # Enhance query with user preferences if user_id is provided (but limit influence)
            enhanced_query = enriched_user_query
            if user_id:
                user_preferences = self.db.get_user_preferences(user_id)
                if user_preferences:
                    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ —Ç–∏–ø–∞–º –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                    pref_by_type = {}
                    for pref in user_preferences:
                        pref_type = pref['preference_type']
                        if pref_type not in pref_by_type:
                            pref_by_type[pref_type] = []
                        pref_by_type[pref_type].append(pref['preference_value'])
                    
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤–ª–∏—è–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π - –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ 2-3 —ç–ª–µ–º–µ–Ω—Ç–∞ –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞
                    limited_preferences = []
                    for pref_type, values in pref_by_type.items():
                        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ 2 —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞
                        limited_values = values[:2]
                        for value in limited_values:
                            limited_preferences.append(f"{pref_type}: {value}")
                    
                    if limited_preferences:
                        preferences_text = " ".join(limited_preferences)
                        enhanced_query = f"{enriched_user_query}\n\nUser preferences (consider moderately): {preferences_text}"

                # Also include user ratings if available (but limit to best rated movies only)
                if user_ratings:
                    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∏–ª—å–º—ã —Å –æ—Ü–µ–Ω–∫–æ–π 8+ –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 3
                    high_rated = [rating for rating in user_ratings if rating['rating'] >= 8][:3]
                    if high_rated:
                        ratings_text = " ".join([f"{rating['title']}: {rating['rating']}/10"
                                                 for rating in high_rated])
                        enhanced_query = f"{enhanced_query}\n\nUser's favorite movies: {ratings_text}"

            # Add instruction to avoid already rated movies
            if excluded_movies:
                excluded_text = ", ".join(excluded_movies[:10])  # Limit to avoid too long prompt
                enhanced_query = f"{enhanced_query}\n\nDO NOT recommend these already rated movies: {excluded_text}"

            # Generate recommendations using Gemini
            system_prompt = """–¢—ã - –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ñ–∏–ª—å–º–æ–≤. –ü—Ä–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ñ–∏–ª—å–º–æ–≤:

–í–ê–ñ–ù–û:
1. –£–∫–∞–∑—ã–≤–∞–π –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∏–ª—å–º—ã —Å —Ç–æ—á–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
2. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∑—ã–≤–∞–π –≥–æ–¥ –≤—ã–ø—É—Å–∫–∞ —Ñ–∏–ª—å–º–∞ –≤ —Å–∫–æ–±–∫–∞—Ö –ø–æ—Å–ª–µ –Ω–∞–∑–≤–∞–Ω–∏—è
3. –ü—Ä–æ–≤–µ—Ä—è–π —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–π - –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∏–ª—å–º—ã
4. –§–æ—Ä–º–∞—Ç–∏—Ä—É–π –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞–∫: **"–¢–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞" (–ì–æ–¥)**
5. –†–µ–∫–æ–º–µ–Ω–¥—É–π 3-5 —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö —Ñ–∏–ª—å–º–æ–≤
6. –ò–∑–±–µ–≥–∞–π —Ñ–∏–ª—å–º–æ–≤ –æ–¥–Ω–æ–≥–æ —Ä–µ–∂–∏—Å—Å–µ—Ä–∞ –∏–ª–∏ —Ñ—Ä–∞–Ω—à–∏–∑—ã, –µ—Å–ª–∏ –Ω–µ –ø—Ä–æ—Å—è—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ
7. –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–π —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∂–∞–Ω—Ä–æ–≤, –≥–æ–¥–æ–≤ –∏ —Å—Ç–∏–ª–µ–π
8. –ö—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏, –ø–æ—á–µ–º—É –∫–∞–∂–¥—ã–π —Ñ–∏–ª—å–º –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ–¥ –∑–∞–ø—Ä–æ—Å
9. –ò–°–ü–û–õ–¨–ó–£–ô –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ TMDB –¥–ª—è —Ç–æ—á–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
10. –ï—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∞–∫—Ç–µ—Ä–∞—Ö/—Ä–µ–∂–∏—Å—Å–µ—Ä–∞—Ö –∏–∑ TMDB, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É—á–∏—Ç—ã–≤–∞–π –∏—Ö —Ñ–∏–ª—å–º–æ–≥—Ä–∞—Ñ–∏—é

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
–í—Å—Ç—É–ø–∏—Ç–µ–ª—å–Ω–∞—è —Ñ—Ä–∞–∑–∞...

**"–ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞ 1" (–ì–æ–¥)**. –ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—á–µ–º—É –ø–æ–¥—Ö–æ–¥–∏—Ç.

**"–ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞ 2" (–ì–æ–¥)**. –ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—á–µ–º—É –ø–æ–¥—Ö–æ–¥–∏—Ç.

–ò —Ç–∞–∫ –¥–∞–ª–µ–µ...

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""

            full_prompt = f"{system_prompt}\n\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–π —Ñ–∏–ª—å–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {enhanced_query}"

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –º–µ–Ω—å—à–µ–≥–æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
            generation_config = {
                "temperature": 0.7,
                "top_p": 0.95,
                "top_k": 40,
                "max_output_tokens": 800,  # –°–Ω–∏–∂–µ–Ω–æ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
            }

            # –ë–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            safety_settings = [
                {
                    "category": "HARM_CATEGORY_HARASSMENT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    "category": "HARM_CATEGORY_HATE_SPEECH",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                }
            ]

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –∫–≤–æ—Ç—ã
            max_retries = 3
            retry_delay = 2  # —Å–µ–∫—É–Ω–¥—ã

            for attempt in range(max_retries):
                try:
                    # If we encountered location restrictions, try with proxy
                    if self.use_proxy:
                        # Get a working proxy
                        proxy = await self._get_working_proxy()
                        if proxy:
                            # Can't directly use proxy with Google client library,
                            # so we'll need to use a raw API request

                            # This would require implementation of a custom function to call the API with proxy
                            # For demonstration, we'll show an error that we need a custom solution
                            error_msg = "–ü—Ä–æ–∫—Å–∏-—Ä–µ—à–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç custom-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å VPN –∏–ª–∏ –¥—Ä—É–≥–æ–π —Å–ø–æ—Å–æ–± –¥–æ—Å—Ç—É–ø–∞ –∫ API."
                            logger.warning(error_msg)
                            return {
                                "original_query": user_query,
                                "error": "Location not supported",
                                "recommendations": [],
                                "llm_response": f"""–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ API Google Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ.

–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—à–µ–Ω–∏—è:
1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ VPN –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ API
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–æ–π API –∫–ª—é—á, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —á–µ—Ä–µ–∑ –∞–∫–∫–∞—É–Ω—Ç –≤ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–º —Ä–µ–≥–∏–æ–Ω–µ
3. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–∞

–í –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, –≤–æ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ñ–∏–ª—å–º—ã:
1. "–ò–Ω—Ç–µ—Ä—Å—Ç–µ–ª–ª–∞—Ä" (2014) - –Ω–∞—É—á–Ω–æ-—Ñ–∞–Ω—Ç–∞—Å—Ç–∏—á–µ—Å–∫–∏–π —Ñ–∏–ª—å–º –æ –∫–æ—Å–º–∏—á–µ—Å–∫–∏—Ö –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è—Ö
2. "–ó–µ–ª–µ–Ω–∞—è –º–∏–ª—è" (1999) - –¥—Ä–∞–º–∞ –æ –Ω–∞–¥–∑–∏—Ä–∞—Ç–µ–ª–µ –≤ —Ç—é—Ä—å–º–µ –∏ –∑–∞–∫–ª—é—á–µ–Ω–Ω–æ–º —Å –Ω–µ–æ–±—ã—á–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è–º–∏
3. "–û—Å—Ç—Ä–æ–≤ –ø—Ä–æ–∫–ª—è—Ç—ã—Ö" (2010) - –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ç—Ä–∏–ª–ª–µ—Ä —Å –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–π –∫–æ–Ω—Ü–æ–≤–∫–æ–π
4. "–ë–æ–π—Ü–æ–≤—Å–∫–∏–π –∫–ª—É–±" (1999) - –∫—É–ª—å—Ç–æ–≤—ã–π —Ñ–∏–ª—å–º –æ —Ç–∞–π–Ω–æ–º –æ–±—â–µ—Å—Ç–≤–µ
5. "–ù–∞—á–∞–ª–æ" (2010) - —Ñ–∏–ª—å–º –æ –ø—Ä–æ–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –≤ —Å–Ω—ã –ª—é–¥–µ–π"""
                            }

                    # Without proxy, try regular API call
                    response = self.model.generate_content(
                        full_prompt,
                        generation_config=generation_config,
                        safety_settings=safety_settings
                    )
                    llm_response = response.text
                    break
                except Exception as e:
                    error_message = str(e)
                    logger.error(f"API error (attempt {attempt + 1}/{max_retries}): {error_message}")

                    if "429" in error_message and attempt < max_retries - 1:
                        logger.warning(
                            f"Rate limit hit, retrying in {retry_delay} seconds... ({attempt + 1}/{max_retries})")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É —Å –∫–∞–∂–¥–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
                    elif "403" in error_message or "User location is not supported" in error_message:
                        # Enable proxy mode for future calls
                        self.use_proxy = True
                        logger.warning("Location restriction detected, enabling proxy fallback")

                        # If we're on the last attempt, return helpful error
                        if attempt == max_retries - 1:
                            error_info = """–î–æ—Å—Ç—É–ø –∫ API –∑–∞–ø—Ä–µ—â–µ–Ω –∏–∑-–∑–∞ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π.

–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:
1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å VPN –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ API
2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π API –∫–ª—é—á –∏–∑ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞
3. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–∞"""
                            logger.error(error_info)

                            # Return fallback recommendations
                            return {
                                "original_query": user_query,
                                "error": "Location not supported",
                                "recommendations": [],
                                "llm_response": f"""–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ API Google Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ.

–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—à–µ–Ω–∏—è:
1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ VPN –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ API
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–æ–π API –∫–ª—é—á, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —á–µ—Ä–µ–∑ –∞–∫–∫–∞—É–Ω—Ç –≤ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–º —Ä–µ–≥–∏–æ–Ω–µ
3. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–∞

–í –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, –≤–æ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ñ–∏–ª—å–º—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É "{user_query}":
1. "–ò–Ω—Ç–µ—Ä—Å—Ç–µ–ª–ª–∞—Ä" (2014) - –Ω–∞—É—á–Ω–æ-—Ñ–∞–Ω—Ç–∞—Å—Ç–∏—á–µ—Å–∫–∏–π —Ñ–∏–ª—å–º –æ –∫–æ—Å–º–∏—á–µ—Å–∫–∏—Ö –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è—Ö
2. "–ó–µ–ª–µ–Ω–∞—è –º–∏–ª—è" (1999) - –¥—Ä–∞–º–∞ –æ –Ω–∞–¥–∑–∏—Ä–∞—Ç–µ–ª–µ –≤ —Ç—é—Ä—å–º–µ –∏ –∑–∞–∫–ª—é—á–µ–Ω–Ω–æ–º —Å –Ω–µ–æ–±—ã—á–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è–º–∏
3. "–û—Å—Ç—Ä–æ–≤ –ø—Ä–æ–∫–ª—è—Ç—ã—Ö" (2010) - –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ç—Ä–∏–ª–ª–µ—Ä —Å –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–π –∫–æ–Ω—Ü–æ–≤–∫–æ–π
4. "–ë–æ–π—Ü–æ–≤—Å–∫–∏–π –∫–ª—É–±" (1999) - –∫—É–ª—å—Ç–æ–≤—ã–π —Ñ–∏–ª—å–º –æ —Ç–∞–π–Ω–æ–º –æ–±—â–µ—Å—Ç–≤–µ
5. "–ù–∞—á–∞–ª–æ" (2010) - —Ñ–∏–ª—å–º –æ –ø—Ä–æ–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –≤ —Å–Ω—ã –ª—é–¥–µ–π"""
                            }
                    else:
                        raise
            else:
                # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
                raise Exception("–ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ API. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

            # Parse the LLM response to extract movie titles
            movie_titles = self._extract_movie_titles(llm_response)

            # Fetch additional details for each movie from TMDB
            detailed_recommendations = []
            validation_summary = {
                'total_extracted': len(movie_titles),
                'excluded_already_rated': 0,
                'excluded_validation_failed': 0,
                'excluded_not_found': 0,
                'included': 0
            }
            
            excluded_movies_info = []  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö —Ñ–∏–ª—å–º–æ–≤
            
            for title in movie_titles:
                # Skip movies that user has already rated
                if title in excluded_movies:
                    logger.info(f"Skipping already rated movie: {title}")
                    validation_summary['excluded_already_rated'] += 1
                    continue
                    
                movie_details = await self._get_movie_details_from_tmdb(title)
                if not movie_details:
                    logger.info(f"Movie not found in TMDB: {title}")
                    validation_summary['excluded_not_found'] += 1
                    excluded_movies_info.append(f'"{title}" - –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ TMDB')
                    continue
                
                # Double-check movie isn't in excluded list (by different title variations)
                movie_title = movie_details.get('title', '')
                original_title = movie_details.get('original_title', '')
                
                is_excluded = False
                for excluded in excluded_movies:
                    if (excluded.lower() in movie_title.lower() or 
                        movie_title.lower() in excluded.lower() or
                        (original_title and (excluded.lower() in original_title.lower() or 
                                            original_title.lower() in excluded.lower()))):
                        is_excluded = True
                        break
                
                if not is_excluded:
                    # –ù–û–í–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ñ–∏–ª—å–º–∞ –∑–∞–ø—Ä–æ—Å—É
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                    is_valid = await self._validate_movie_match(movie_details, enriched_user_query, title)
                    
                    if is_valid:
                        detailed_recommendations.append(movie_details)
                        validation_summary['included'] += 1

                        # Save movie to database if not already present
                        existing_movie = self.db.get_movie_by_tmdb_id(movie_details.get('tmdb_id'))
                        if not existing_movie:
                            self.db.add_movie(movie_details)
                    else:
                        logger.info(f"Skipping invalid movie: '{movie_title}' - doesn't match user request")
                        validation_summary['excluded_validation_failed'] += 1
                        excluded_movies_info.append(f'"{movie_title}" - –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–ø—Ä–æ—Å—É')
                else:
                    logger.info(f"Skipping excluded movie variant: {movie_title}")
                    validation_summary['excluded_already_rated'] += 1

            # –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê: –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–µ –≤–∞–ª–∏–¥–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            retry_count = 0
            max_retries = 2
            
            while (validation_summary['included'] < 2 and 
                   validation_summary['excluded_validation_failed'] > 0 and 
                   retry_count < max_retries):
                
                retry_count += 1
                logger.info(f"Attempting retry {retry_count} due to insufficient valid recommendations")
                
                # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö —Ñ–∏–ª—å–º–æ–≤ –¥–ª—è –ò–ò
                excluded_list = ", ".join(excluded_movies_info[-5:])  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö
                
                # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                retry_prompt = f"""–ü–µ—Ä–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–ª–∞ –Ω–µ—Ç–æ—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∏–ª—å–º—ã –±—ã–ª–∏ –∏—Å–∫–ª—é—á–µ–Ω—ã: {excluded_list}

–í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—å —Ç–æ—á–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏!
- –ù–ï –≤—ã–¥—É–º—ã–≤–∞–π —É—á–∞—Å—Ç–∏–µ –∞–∫—Ç–µ—Ä–æ–≤ –≤ —Ñ–∏–ª—å–º–∞—Ö, –≥–¥–µ –æ–Ω–∏ –Ω–µ —Å–Ω–∏–º–∞–ª–∏—Å—å
- –£–∫–∞–∑—ã–≤–∞–π –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç—ã –æ–± –∞–∫—Ç–µ—Ä–∞—Ö –∏ —Ä–µ–∂–∏—Å—Å–µ—Ä–∞—Ö
- –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ —É—á–∞—Å—Ç–∏–∏ –∞–∫—Ç–µ—Ä–∞ –≤ —Ñ–∏–ª—å–º–µ - –ù–ï —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –µ–≥–æ

–ü–û–í–¢–û–†–ù–´–ô –ó–ê–ü–†–û–°: {enhanced_query}

–ü–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–π 3-4 –î–†–£–ì–ò–• —Ñ–∏–ª—å–º–∞ (–Ω–µ –∏–∑ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö), –ø—Ä–æ–≤–µ—Ä–∏–≤ —Ç–æ—á–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–∫—Ç–µ—Ä–∞—Ö/—Ä–µ–∂–∏—Å—Å–µ—Ä–∞—Ö."""

                try:
                    retry_response = self.model.generate_content(
                        retry_prompt,
                        generation_config=generation_config,
                        safety_settings=safety_settings
                    )
                    retry_llm_response = retry_response.text
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                    retry_movie_titles = self._extract_movie_titles(retry_llm_response)
                    logger.info(f"Retry {retry_count} extracted {len(retry_movie_titles)} movies: {retry_movie_titles}")
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                    for title in retry_movie_titles:
                        # –ò–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∏–ª—å–º–æ–≤
                        already_processed = any(title.lower() in processed_title.lower() 
                                              for processed_title in movie_titles)
                        if already_processed:
                            continue
                            
                        if title in excluded_movies:
                            continue
                            
                        movie_details = await self._get_movie_details_from_tmdb(title)
                        if not movie_details:
                            excluded_movies_info.append(f'"{title}" - –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ TMDB (retry {retry_count})')
                            continue
                        
                        movie_title = movie_details.get('title', '')
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ —É–∂–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö
                        is_duplicate = any(rec.get('title', '').lower() == movie_title.lower() 
                                         for rec in detailed_recommendations)
                        if is_duplicate:
                            continue
                        
                        is_valid = await self._validate_movie_match(movie_details, enriched_user_query, title)
                        
                        if is_valid:
                            detailed_recommendations.append(movie_details)
                            validation_summary['included'] += 1
                            movie_titles.append(title)  # –î–æ–±–∞–≤–ª—è–µ–º –∫ –æ–±—â–µ–º—É —Å–ø–∏—Å–∫—É
                            logger.info(f"Added valid movie from retry {retry_count}: {movie_title}")

                            existing_movie = self.db.get_movie_by_tmdb_id(movie_details.get('tmdb_id'))
                            if not existing_movie:
                                self.db.add_movie(movie_details)
                                
                            # –ï—Å–ª–∏ –Ω–∞–±—Ä–∞–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, –ø—Ä–µ—Ä—ã–≤–∞–µ–º
                            if validation_summary['included'] >= 3:
                                break
                        else:
                            validation_summary['excluded_validation_failed'] += 1
                            excluded_movies_info.append(f'"{movie_title}" - –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–ø—Ä–æ—Å—É (retry {retry_count})')
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º LLM –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                    if retry_count == 1:
                        llm_response += f"\n\nüìù –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏):\n{retry_llm_response}"
                    
                except Exception as e:
                    logger.error(f"Error during retry {retry_count}: {e}")
                    break

            # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            logger.info(f"Final validation summary after {retry_count} retries: {validation_summary}")
            
            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –≤—Å–µ –µ—â–µ –º–∞–ª–æ —Ñ–∏–ª—å–º–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ—è—Å–Ω–µ–Ω–∏–µ
            if validation_summary['included'] < 2 and validation_summary['excluded_validation_failed'] > 0:
                additional_info = f"\n\n‚ö†Ô∏è –ü–æ—Å–ª–µ {retry_count} –ø–æ–ø—ã—Ç–æ–∫ —É–ª—É—á—à–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∏–ª—å–º—ã –≤—Å–µ –µ—â–µ –±—ã–ª–∏ –∏—Å–∫–ª—é—á–µ–Ω—ã –∏–∑-–∑–∞ –Ω–µ—Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–Ω–∞–π–¥–µ–Ω–æ {validation_summary['excluded_validation_failed']} –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π)."
                llm_response += additional_info
            elif retry_count > 0 and validation_summary['included'] >= 2:
                additional_info = f"\n\n‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —É–ª—É—á—à–µ–Ω—ã –ø–æ—Å–ª–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ (–ø–æ–ø—ã—Ç–æ–∫: {retry_count})."
                llm_response += additional_info

            return {
                "original_query": user_query,
                "llm_response": llm_response,
                "recommendations": detailed_recommendations
            }

        except Exception as e:
            error_message = str(e)
            logger.error(f"Error generating recommendations: {error_message}")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            user_friendly_message = error_message

            if "403" in error_message or "User location is not supported" in error_message:
                # Set proxy mode for future requests
                self.use_proxy = True

                user_friendly_message = """–î–æ—Å—Ç—É–ø –∫ Google Gemini API –∑–∞–ø—Ä–µ—â–µ–Ω –∏–∑ –≤–∞—à–µ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞.

–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—à–µ–Ω–∏—è:
1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ VPN –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ API
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–æ–π API –∫–ª—é—á –∏–∑ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞
3. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ API

–í –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, –≤–æ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ñ–∏–ª—å–º—ã:
1. "–ò–Ω—Ç–µ—Ä—Å—Ç–µ–ª–ª–∞—Ä" (2014) - –Ω–∞—É—á–Ω–æ-—Ñ–∞–Ω—Ç–∞—Å—Ç–∏—á–µ—Å–∫–∏–π —Ñ–∏–ª—å–º –æ –∫–æ—Å–º–∏—á–µ—Å–∫–∏—Ö –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è—Ö
2. "–ó–µ–ª–µ–Ω–∞—è –º–∏–ª—è" (1999) - –¥—Ä–∞–º–∞ –æ –Ω–∞–¥–∑–∏—Ä–∞—Ç–µ–ª–µ –≤ —Ç—é—Ä—å–º–µ –∏ –∑–∞–∫–ª—é—á–µ–Ω–Ω–æ–º —Å –Ω–µ–æ–±—ã—á–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è–º–∏
3. "–û—Å—Ç—Ä–æ–≤ –ø—Ä–æ–∫–ª—è—Ç—ã—Ö" (2010) - –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ç—Ä–∏–ª–ª–µ—Ä —Å –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–π –∫–æ–Ω—Ü–æ–≤–∫–æ–π
4. "–ë–æ–π—Ü–æ–≤—Å–∫–∏–π –∫–ª—É–±" (1999) - –∫—É–ª—å—Ç–æ–≤—ã–π —Ñ–∏–ª—å–º –æ —Ç–∞–π–Ω–æ–º –æ–±—â–µ—Å—Ç–≤–µ
5. "–ù–∞—á–∞–ª–æ" (2010) - —Ñ–∏–ª—å–º –æ –ø—Ä–æ–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –≤ —Å–Ω—ã –ª—é–¥–µ–π"""
            elif "429" in error_message:
                user_friendly_message = "–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            elif "404" in error_message:
                user_friendly_message = "–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í–æ–∑–º–æ–∂–Ω–æ, –≤—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –≤–∞—à–µ–≥–æ API –∫–ª—é—á–∞."

            return {
                "original_query": user_query,
                "error": error_message,
                "recommendations": [],
                "llm_response": f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {user_friendly_message}"
            }

    def _extract_movie_titles(self, llm_response: str) -> List[str]:
        """
        Extract movie titles from the LLM response.

        Args:
            llm_response: Text response from Gemini

        Returns:
            List of extracted movie titles
        """
        try:
            # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Ñ–∏–ª—å–º–æ–≤
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ **"–ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞" (–ì–æ–¥)** –∏–ª–∏ "–ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞" (–ì–æ–¥)
            title_patterns = [
                r'\*\*"([^"]+)"\s*\((\d{4})\)\*\*',  # **"Title" (Year)**
                r'"([^"]+)"\s*\((\d{4})\)',           # "Title" (Year)
                r'\*\*([^*]+)\*\*\s*\((\d{4})\)',    # **Title** (Year)
                r'¬´([^¬ª]+)¬ª\s*\((\d{4})\)',           # ¬´Title¬ª (Year) - —Ä—É—Å—Å–∫–∏–µ –∫–∞–≤—ã—á–∫–∏
                r'"([^"]+)"\s*\((\d{4})\)',           # "Title" (Year) - –æ–±—ã—á–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
            ]
            
            extracted_titles = []
            
            # –ü—Ä–æ–±—É–µ–º –∫–∞–∂–¥—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
            for pattern in title_patterns:
                matches = re.findall(pattern, llm_response)
                for match in matches:
                    if len(match) == 2:  # title, year
                        title, year = match
                        full_title = f"{title.strip()} ({year})"
                        if full_title not in extracted_titles:
                            extracted_titles.append(full_title)
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ñ–∏–ª—å–º—ã —Å –≥–æ–¥–∞–º–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Ö
            if extracted_titles:
                logger.info(f"Extracted titles with years: {extracted_titles}")
                return extracted_titles
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å –≥–æ–¥–∞–º–∏, –∏—â–µ–º –ø—Ä–æ—Å—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏—è –≤ –∫–∞–≤—ã—á–∫–∞—Ö/–∑–≤–µ–∑–¥–æ—á–∫–∞—Ö
            simple_patterns = [
                r'\*\*"([^"]+)"\*\*',     # **"Title"**
                r'"([^"]+)"',             # "Title"
                r'\*\*([^*]+)\*\*',       # **Title**
                r'¬´([^¬ª]+)¬ª',             # ¬´Title¬ª
            ]
            
            for pattern in simple_patterns:
                matches = re.findall(pattern, llm_response)
                for title in matches:
                    title = title.strip()
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–ª–∏ —è–≤–Ω–æ –Ω–µ —è–≤–ª—è—é—â–∏–µ—Å—è –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ —Å—Ç—Ä–æ–∫–∏
                    if len(title) > 3 and not title.lower() in ['–≥–æ–¥', '—Ñ–∏–ª—å–º', '–≥–æ–¥–∞', 'this', 'that']:
                        if title not in extracted_titles:
                            extracted_titles.append(title)
            
            if extracted_titles:
                logger.info(f"Extracted simple titles: {extracted_titles}")
                return extracted_titles

            # –ï—Å–ª–∏ –∏ —ç—Ç–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º LLM –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è (–±–æ–ª–µ–µ –∑–∞—Ç—Ä–∞—Ç–Ω–æ)
            extraction_prompt = f"""–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ–∫–∏ –¢–û–ß–ù–´–ï –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∏–ª—å–º–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö.
            
–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ JSON –º–∞—Å—Å–∏–≤–∞ —Å—Ç—Ä–æ–∫ –≤ —Ñ–æ—Ä–º–∞—Ç–µ '–ù–∞–∑–≤–∞–Ω–∏–µ (–ì–æ–¥)' –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ '–ù–∞–∑–≤–∞–Ω–∏–µ', –µ—Å–ª–∏ –≥–æ–¥ –Ω–µ —É–∫–∞–∑–∞–Ω.
–ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –Ω–∞–∑–≤–∞–Ω–∏—è - –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –µ—Å—Ç—å –≤ —Ç–µ–∫—Å—Ç–µ.

–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
{llm_response}

–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON –º–∞—Å—Å–∏–≤, –Ω–∏—á–µ–≥–æ –±–æ–ª—å—à–µ."""

            # –ë–æ–ª–µ–µ —ç–∫–æ–Ω–æ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            generation_config = {
                "temperature": 0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                "top_p": 0.95,
                "top_k": 40,
                "max_output_tokens": 300,  # –ú–µ–Ω—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤
            }

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –∫–≤–æ—Ç—ã
            max_retries = 2
            retry_delay = 1  # —Å–µ–∫—É–Ω–¥—ã

            for attempt in range(max_retries):
                try:
                    response = self.model.generate_content(
                        extraction_prompt,
                        generation_config=generation_config
                    )
                    extraction_result = response.text
                    break
                except Exception as e:
                    if "429" in str(e) and attempt < max_retries - 1:
                        logger.warning(f"Rate limit hit during extraction, retrying in {retry_delay} seconds...")
                        time.sleep(retry_delay)
                        retry_delay *= 2
                    else:
                        logger.warning(f"LLM extraction failed: {e}, using regex fallback")
                        return []
            else:
                return []

            # Try to parse JSON from the response
            try:
                # Look for JSON array in the response
                json_match = re.search(r'\[.*\]', extraction_result, re.DOTALL)
                if json_match:
                    titles = json.loads(json_match.group(0))
                    logger.info(f"LLM extracted titles: {titles}")
                    return titles

                # If no JSON array found, try to extract titles with regex
                titles = re.findall(r'"([^"]+)"', extraction_result)
                if titles:
                    logger.info(f"LLM fallback extracted titles: {titles}")
                    return titles

                return []

            except json.JSONDecodeError:
                logger.warning("Failed to parse LLM JSON response")
                return []

        except Exception as e:
            logger.error(f"Error extracting movie titles: {e}")
            return []

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ - –≤—ã–Ω–µ—Å–µ–º –µ–µ –Ω–∞ —É—Ä–æ–≤–µ–Ω—å –∫–ª–∞—Å—Å–∞
    def _normalize_text(self, text):
        if not text:
            return ""
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å—Ç—Ä–æ–∫–∞
        if not isinstance(text, str):
            try:
                return str(text)
            except:
                return ""
        return text

    async def _get_movie_details_from_tmdb(self, movie_title: str) -> Optional[Dict[str, Any]]:
        """
        Get movie details from TMDB API.

        Args:
            movie_title: Movie title to search for

        Returns:
            Dictionary with movie details or None if not found
        """
        try:
            # Extract year from title if present
            import re
            year_match = re.search(r'\((\d{4})\)', movie_title)
            year = year_match.group(1) if year_match else None

            # Clean title by removing year and extra formatting
            clean_title = re.sub(r'\s*\(\d{4}\)', '', movie_title).strip()
            clean_title = clean_title.strip('"¬´¬ª*')  # Remove quotes and formatting
            
            logger.info(f"Searching for movie: '{clean_title}' (year: {year})")

            # Use httpx instead of requests for better SSL handling
            async with httpx.AsyncClient(timeout=30.0, verify=True) as client:
                # Search for movie in TMDB
                search_url = f"{self.tmdb_base_url}/search/movie"
                params = {
                    "api_key": self.tmdb_api_key,
                    "query": clean_title,
                    "language": "ru-RU"
                }
                if year:
                    params["year"] = year

                # Try up to 3 times with increasing timeout
                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        response = await client.get(search_url, params=params)
                        response.raise_for_status()
                        search_results = response.json()
                        break
                    except (httpx.ConnectError, httpx.ReadError, httpx.ConnectTimeout, 
                            httpx.ReadTimeout, ssl.SSLError) as e:
                        if attempt < max_retries - 1:
                            wait_time = (attempt + 1) * 2  # Exponential backoff
                            logger.warning(f"TMDB search attempt {attempt+1} failed: {e}. Retrying in {wait_time}s...")
                            await asyncio.sleep(wait_time)
                        else:
                            logger.error(f"All TMDB search attempts failed: {e}")
                            return None
                else:
                    # All attempts failed
                    return None

                if not search_results.get('results'):
                    logger.warning(f"No TMDB results found for movie: {movie_title}")
                    # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–∏—Å–∫ –±–µ–∑ –≥–æ–¥–∞, –µ—Å–ª–∏ –±—ã–ª —É–∫–∞–∑–∞–Ω –≥–æ–¥
                    if year:
                        logger.info(f"Retrying search without year for: {clean_title}")
                        params_no_year = {
                            "api_key": self.tmdb_api_key,
                            "query": clean_title,
                            "language": "ru-RU"
                        }
                        try:
                            response = await client.get(search_url, params=params_no_year)
                            response.raise_for_status()
                            search_results = response.json()
                        except:
                            logger.error(f"Retry search also failed for: {clean_title}")
                            return None
                    
                    if not search_results.get('results'):
                        return None

                # Find the best match
                best_match = None
                best_score = 0
                
                for movie in search_results['results'][:5]:  # Check top 5 results
                    movie_title_tmdb = movie.get('title', '').lower()
                    original_title_tmdb = movie.get('original_title', '').lower()
                    release_date = movie.get('release_date', '')
                    movie_year = release_date[:4] if release_date else None
                    
                    # Calculate similarity score
                    score = 0
                    clean_title_lower = clean_title.lower()
                    
                    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
                    if clean_title_lower == movie_title_tmdb or clean_title_lower == original_title_tmdb:
                        score += 100
                    
                    # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
                    elif clean_title_lower in movie_title_tmdb or movie_title_tmdb in clean_title_lower:
                        score += 80
                    elif clean_title_lower in original_title_tmdb or original_title_tmdb in clean_title_lower:
                        score += 75
                    
                    # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                    clean_words = set(clean_title_lower.split())
                    title_words = set(movie_title_tmdb.split())
                    original_words = set(original_title_tmdb.split())
                    
                    # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–∏—Ö —Å–ª–æ–≤
                    common_with_title = len(clean_words.intersection(title_words))
                    common_with_original = len(original_words.intersection(clean_words))
                    max_common = max(common_with_title, common_with_original)
                    
                    if max_common > 0:
                        score += max_common * 20
                    
                    # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≥–æ–¥–∞
                    if year and movie_year == year:
                        score += 50
                    
                    # –®—Ç—Ä–∞—Ñ –∑–∞ –±–æ–ª—å—à–æ–µ —Ä–∞–∑–ª–∏—á–∏–µ –≤ –≥–æ–¥—É
                    if year and movie_year and abs(int(year) - int(movie_year)) > 2:
                        score -= 30
                    
                    logger.info(f"Movie: '{movie_title_tmdb}' ({movie_year}) - Score: {score}")
                    
                    if score > best_score:
                        best_score = score
                        best_match = movie

                # –ï—Å–ª–∏ –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–º–µ–µ—Ç —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∏–π —Ä–µ–π—Ç–∏–Ω–≥, –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ
                if best_score < 40:
                    logger.warning(f"Best match score too low ({best_score}) for: {movie_title}")
                    return None

                if not best_match:
                    logger.warning(f"No suitable match found for: {movie_title}")
                    return None

                logger.info(f"Selected movie: '{best_match.get('title')}' ({best_match.get('release_date', '')[:4]}) with score: {best_score}")

                # Get detailed info for the best match
                movie_id = best_match['id']
                details_url = f"{self.tmdb_base_url}/movie/{movie_id}"
                params = {
                    "api_key": self.tmdb_api_key,
                    "language": "ru-RU",
                    "append_to_response": "credits,similar"
                }

                # Try up to 3 times with increasing timeout
                for attempt in range(max_retries):
                    try:
                        response = await client.get(details_url, params=params)
                        response.raise_for_status()
                        details = response.json()
                        break
                    except (httpx.ConnectError, httpx.ReadError, httpx.ConnectTimeout, 
                            httpx.ReadTimeout, ssl.SSLError) as e:
                        if attempt < max_retries - 1:
                            wait_time = (attempt + 1) * 2  # Exponential backoff
                            logger.warning(f"TMDB details attempt {attempt+1} failed: {e}. Retrying in {wait_time}s...")
                            await asyncio.sleep(wait_time)
                        else:
                            logger.error(f"All TMDB details attempts failed: {e}")
                            return None
                else:
                    # All attempts failed
                    return None

                # Extract directors and actors
                directors = []
                actors = []

                if 'credits' in details:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∂–∏—Å—Å–µ—Ä–æ–≤ –∏ —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –æ–Ω–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏
                    for crew in details['credits'].get('crew', []):
                        if crew.get('job') == 'Director':
                            director_name = self._normalize_text(crew.get('name', ''))
                            if director_name:
                                directors.append(director_name)

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–∫—Ç–µ—Ä–æ–≤ –∏ —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –æ–Ω–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏
                    for cast in details['credits'].get('cast', []):
                        if cast.get('order', 999) < 5:  # Get top 5 billed actors
                            actor_name = self._normalize_text(cast.get('name', ''))
                            if actor_name:
                                actors.append(actor_name)

                # Extract genres as strings
                genres = []
                for genre in details.get('genres', []):
                    genre_name = self._normalize_text(genre.get('name', ''))
                    if genre_name:
                        genres.append(genre_name)

                # Create movie details dictionary with normalized text
                movie_data = {
                    'tmdb_id': details['id'],
                    'title': self._normalize_text(details['title']),
                    'original_title': self._normalize_text(details.get('original_title')),
                    'overview': self._normalize_text(details.get('overview')),
                    'release_date': self._normalize_text(details.get('release_date')),
                    'poster_path': self._normalize_text(details.get('poster_path')),
                    'genres': genres,
                    'runtime': details.get('runtime'),
                    'vote_average': details.get('vote_average'),
                    'vote_count': details.get('vote_count'),
                    'popularity': details.get('popularity'),
                    'directors': directors,
                    'actors': actors
                }

                logger.info(f"Successfully found movie: {movie_data['title']} ({movie_data['release_date'][:4] if movie_data['release_date'] else 'N/A'})")
                return movie_data

        except Exception as e:
            logger.error(f"Error getting movie details from TMDB: {e}")
            return None

    async def process_user_feedback(self, user_id: int, movie_id: int, rating: int) -> bool:
        """
        Process user feedback on a movie recommendation.

        Args:
            user_id: Telegram user ID
            movie_id: Database ID of the movie
            rating: User rating (1-10)

        Returns:
            True if feedback was processed successfully, False otherwise
        """
        try:
            # Save rating to database
            success = self.db.add_user_rating(user_id, movie_id, rating)

            # Add to user history
            if success:
                self.db.add_user_history(user_id, movie_id, f"rated_{rating}")

            # Extract movie details for preference learning (only for exceptional ratings)
            movie = self.db.get_movie_by_tmdb_id(movie_id)
            if movie and rating >= 9:  # Only learn from exceptional ratings (9-10)
                # Get current user preferences to avoid duplicates and limit quantity
                current_preferences = self.db.get_user_preferences(user_id)
                
                # Count current preferences by type
                pref_counts = {}
                for pref in current_preferences:
                    pref_type = pref['preference_type']
                    pref_counts[pref_type] = pref_counts.get(pref_type, 0) + 1
                
                # Add genre preferences (limit to 5 per type)
                if movie.get('genres') and pref_counts.get('genre', 0) < 5:
                    # Add only the first genre to avoid overwhelming preferences
                    genre = movie['genres'][0] if movie['genres'] else None
                    if genre:
                        # Check if this genre is already in preferences
                        existing_genres = [p['preference_value'] for p in current_preferences 
                                         if p['preference_type'] == 'genre']
                        if genre not in existing_genres:
                            self.db.add_user_preference(user_id, 'genre', genre)

                # Add director preferences (limit to 3 per type, only for 10/10 ratings)
                if movie.get('directors') and rating == 10 and pref_counts.get('director', 0) < 3:
                    # Add only the first director
                    director = movie['directors'][0] if movie['directors'] else None
                    if director:
                        # Check if this director is already in preferences
                        existing_directors = [p['preference_value'] for p in current_preferences 
                                            if p['preference_type'] == 'director']
                        if director not in existing_directors:
                            self.db.add_user_preference(user_id, 'director', director)

            return success
        except Exception as e:
            logger.error(f"Error processing user feedback: {e}")
            return False

    async def get_similar_movies(self, movie_title: str, user_id: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        Get similar movies based on a movie title.

        Args:
            movie_title: Title of the movie to find similarities for
            user_id: Optional user ID to exclude already rated movies

        Returns:
            List of similar movies
        """
        try:
            # Get list of already rated movies to exclude them
            excluded_movies = []
            if user_id:
                user_ratings = self.db.get_user_ratings(user_id)
                excluded_movies = [rating['title'] for rating in user_ratings]

            # First, try to get the movie from our database
            movie = self.db.get_movie_by_title(movie_title)

            # If not in database, search TMDB
            if not movie:
                movie_details = await self._get_movie_details_from_tmdb(movie_title)
                if movie_details:
                    movie = movie_details
                    self.db.add_movie(movie_details)

            if not movie:
                logger.warning(f"Could not find movie: {movie_title}")
                return []

            # Get similar movies from TMDB
            tmdb_id = movie.get('tmdb_id')
            if not tmdb_id:
                return []

            similar_url = f"{self.tmdb_base_url}/movie/{tmdb_id}/similar"
            params = {
                "api_key": self.tmdb_api_key,
                "language": "ru-RU"
            }

            # Use httpx instead of requests for better SSL handling
            async with httpx.AsyncClient(timeout=30.0, verify=True) as client:
                # Try up to 3 times with increasing timeout
                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        response = await client.get(similar_url, params=params)
                        response.raise_for_status()
                        similar_results = response.json()
                        break
                    except (httpx.ConnectError, httpx.ReadError, httpx.ConnectTimeout, 
                            httpx.ReadTimeout, ssl.SSLError) as e:
                        if attempt < max_retries - 1:
                            wait_time = (attempt + 1) * 2  # Exponential backoff
                            logger.warning(f"TMDB similar movies attempt {attempt+1} failed: {e}. Retrying in {wait_time}s...")
                            await asyncio.sleep(wait_time)
                        else:
                            logger.error(f"All TMDB similar movies attempts failed: {e}")
                            return []
                else:
                    # All attempts failed
                    return []

                similar_movies = []
                for similar in similar_results.get('results', [])[:10]:  # Get more candidates to filter from
                    movie_title_candidate = self._normalize_text(similar['title'])
                    
                    # Skip movies that user has already rated
                    is_excluded = False
                    for excluded in excluded_movies:
                        if (excluded.lower() in movie_title_candidate.lower() or 
                            movie_title_candidate.lower() in excluded.lower()):
                            is_excluded = True
                            break
                    
                    if is_excluded:
                        logger.info(f"Skipping already rated similar movie: {movie_title_candidate}")
                        continue
                    
                    movie_details = await self._get_movie_details_from_tmdb(movie_title_candidate)
                    if movie_details:
                        # Double-check against excluded list with original and TMDB titles
                        movie_title = movie_details.get('title', '')
                        original_title = movie_details.get('original_title', '')
                        
                        is_excluded = False
                        for excluded in excluded_movies:
                            if (excluded.lower() in movie_title.lower() or 
                                movie_title.lower() in excluded.lower() or
                                (original_title and (excluded.lower() in original_title.lower() or 
                                                    original_title.lower() in excluded.lower()))):
                                is_excluded = True
                                break
                        
                        if not is_excluded:
                            similar_movies.append(movie_details)
                            self.db.add_movie(movie_details)
                            
                            # Stop when we have enough recommendations
                            if len(similar_movies) >= 5:
                                break
                        else:
                            logger.info(f"Skipping excluded similar movie variant: {movie_title}")

                return similar_movies

        except Exception as e:
            logger.error(f"Error getting similar movies: {e}")
            return []

    async def _validate_movie_match(self, movie_data: Dict[str, Any], user_query: str, recommended_title: str) -> bool:
        """
        Validate if the found movie actually matches the user's request.
        
        Args:
            movie_data: Movie details from TMDB
            user_query: Original user query
            recommended_title: Title that AI recommended
            
        Returns:
            True if movie matches the request, False otherwise
        """
        try:
            # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
            if not movie_data:
                return False
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Ñ–∏–ª—å–º–µ
            title = movie_data.get('title', '')
            original_title = movie_data.get('original_title', '')
            overview = movie_data.get('overview', '')
            genres = movie_data.get('genres', [])
            release_date = movie_data.get('release_date', '')
            year = release_date[:4] if release_date else ''
            actors = movie_data.get('actors', [])
            directors = movie_data.get('directors', [])
            
            # –ù–û–í–ê–Ø –ü–†–û–í–ï–†–ö–ê: –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –∞–∫—Ç–µ—Ä–∞–º–∏
            actor_patterns = [
                r'—Å\s+([–ê-–Ø–Å][–∞-—è—ë]+[—ã–æ–∞—É–µ–π–º—Ö]?\s+[–ê-–Ø–Å][–∞-—è—ë]+[—ã–æ–∞—É–µ–π–º—Ö]?)',
                r'–∞–∫—Ç–µ—Ä[–∞-—è]*\s+([–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?\s+[–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?)',
                r'—É—á–∞—Å—Ç–∏–µ[–º–Ω]\s+([–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?\s+[–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?)',
            ]
            
            requested_actors = set()
            for pattern in actor_patterns:
                matches = re.findall(pattern, user_query)
                for match in matches:
                    normalized_name = self._normalize_person_name(match.strip())
                    requested_actors.add(normalized_name.lower())
            
            # –ï—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ —É–∫–∞–∑–∞–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∞–∫—Ç–µ—Ä, –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ–≥–æ —É—á–∞—Å—Ç–∏–µ
            if requested_actors:
                movie_actors_lower = [actor.lower() for actor in actors]
                
                for requested_actor in requested_actors:
                    found_actor = False
                    for movie_actor in movie_actors_lower:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ (–∏–º—è –∏ —Ñ–∞–º–∏–ª–∏—è)
                        if (requested_actor in movie_actor or 
                            movie_actor in requested_actor or
                            self._names_match(requested_actor, movie_actor)):
                            found_actor = True
                            break
                    
                    if not found_actor:
                        logger.warning(f"Requested actor '{requested_actor}' not found in '{title}' cast: {actors}")
                        return False
            
            # –ù–û–í–ê–Ø –ü–†–û–í–ï–†–ö–ê: –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ —Å —Ä–µ–∂–∏—Å—Å–µ—Ä–∞–º–∏  
            director_patterns = [
                r'–æ—Ç\s+(?:—Ä–µ–∂–∏—Å—Å–µ—Ä–∞\s+)?([–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?\s+[–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?)',
                r'—Ä–µ–∂–∏—Å—Å–µ—Ä[–∞-—è]*\s+([–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?\s+[–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?)',
            ]
            
            requested_directors = set()
            for pattern in director_patterns:
                matches = re.findall(pattern, user_query)
                for match in matches:
                    normalized_name = self._normalize_person_name(match.strip())
                    requested_directors.add(normalized_name.lower())
            
            # –ï—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ —É–∫–∞–∑–∞–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ä–µ–∂–∏—Å—Å–µ—Ä, –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ–≥–æ —É—á–∞—Å—Ç–∏–µ
            if requested_directors:
                movie_directors_lower = [director.lower() for director in directors]
                
                for requested_director in requested_directors:
                    found_director = False
                    for movie_director in movie_directors_lower:
                        if (requested_director in movie_director or 
                            movie_director in requested_director or
                            self._names_match(requested_director, movie_director)):
                            found_director = True
                            break
                    
                    if not found_director:
                        logger.warning(f"Requested director '{requested_director}' not found in '{title}' crew: {directors}")
                        return False
            
            # –°–æ–∑–¥–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            movie_description = f"""
–ù–∞–∑–≤–∞–Ω–∏–µ: {title}
–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: {original_title}
–ì–æ–¥: {year}
–ñ–∞–Ω—Ä—ã: {', '.join(genres)}
–ê–∫—Ç–µ—Ä—ã: {', '.join(actors[:5])}
–†–µ–∂–∏—Å—Å–µ—Ä—ã: {', '.join(directors)}
–û–ø–∏—Å–∞–Ω–∏–µ: {overview}
"""
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ò–ò –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ —Å—Ç—Ä–æ–≥–∏—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ –≤—ã—à–µ)
            if not requested_actors and not requested_directors:
                validation_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ñ–∏–ª—å–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º—É –∑–∞–ø—Ä–æ—Å—É.

–ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô –ó–ê–ü–†–û–°: {user_query}

–†–ï–ö–û–ú–ï–ù–î–û–í–ê–ù–ù–´–ô –ë–û–¢–û–ú –§–ò–õ–¨–ú: {recommended_title}

–ù–ê–ô–î–ï–ù–ù–´–ô –í –ë–ê–ó–ï –§–ò–õ–¨–ú:
{movie_description}

–í–æ–ø—Ä–æ—Å—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
1. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –ª–∏ –∂–∞–Ω—Ä—ã –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ñ–∏–ª—å–º–∞ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è?
2. –ü–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞ –ø–æ–¥ –∑–∞–ø—Ä–æ—Å?
3. –≠—Ç–æ —Ç–æ—Ç –∂–µ —Ñ–∏–ª—å–º, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –±–æ—Ç, –∏–ª–∏ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –¥—Ä—É–≥–æ–π?

–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º:
- "–î–ê" - –µ—Å–ª–∏ —Ñ–∏–ª—å–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–ø—Ä–æ—Å—É
- "–ù–ï–¢" - –µ—Å–ª–∏ —Ñ–∏–ª—å–º –ù–ï —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–ø—Ä–æ—Å—É

–û—Ç–≤–µ—Ç:"""

                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                generation_config = {
                    "temperature": 0.1,
                    "top_p": 0.9,
                    "top_k": 20,
                    "max_output_tokens": 10,  # –û—á–µ–Ω—å –º–∞–ª–æ —Ç–æ–∫–µ–Ω–æ–≤ - –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –î–ê/–ù–ï–¢
                }

                try:
                    response = self.model.generate_content(
                        validation_prompt,
                        generation_config=generation_config
                    )
                    validation_result = response.text.strip().upper()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
                    is_valid = "–î–ê" in validation_result or "YES" in validation_result
                    
                    logger.info(f"AI validation for '{title}': {validation_result} -> {'VALID' if is_valid else 'INVALID'}")
                    return is_valid
                    
                except Exception as e:
                    logger.warning(f"AI validation failed, using fallback validation: {e}")
                    # Fallback –≤–∞–ª–∏–¥–∞—Ü–∏—è –±–µ–∑ –ò–ò
                    return self._fallback_validation(movie_data, user_query)
            
            # –ï—Å–ª–∏ –ø—Ä–æ—à–ª–∏ –≤—Å–µ —Å—Ç—Ä–æ–≥–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
            return True
                
        except Exception as e:
            logger.error(f"Error during movie validation: {e}")
            return True  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Ä–∞–∑—Ä–µ—à–∞–µ–º —Ñ–∏–ª—å–º

    def _names_match(self, name1: str, name2: str) -> bool:
        """
        Check if two names refer to the same person.
        
        Args:
            name1: First name (normalized)
            name2: Second name (from movie data)
            
        Returns:
            True if names likely refer to the same person
        """
        try:
            # –†–∞–∑–±–∏–≤–∞–µ–º –∏–º–µ–Ω–∞ –Ω–∞ —á–∞—Å—Ç–∏
            parts1 = name1.split()
            parts2 = name2.split()
            
            if len(parts1) >= 2 and len(parts2) >= 2:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –∏ —Ñ–∞–º–∏–ª–∏–∏
                first_match = any(p1 in p2 or p2 in p1 for p1 in parts1[:1] for p2 in parts2[:1])
                last_match = any(p1 in p2 or p2 in p1 for p1 in parts1[-1:] for p2 in parts2[-1:])
                
                return first_match and last_match
            
            return False
        except:
            return False

    def _fallback_validation(self, movie_data: Dict[str, Any], user_query: str) -> bool:
        """
        Fallback validation without AI when AI validation fails.
        """
        try:
            genres = [g.lower() for g in movie_data.get('genres', [])]
            query_lower = user_query.lower()
            overview = movie_data.get('overview', '').lower()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –∑–∞–ø—Ä–æ—Å–µ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∂–∞–Ω—Ä–æ–≤
            genre_keywords = {
                '–±–æ–µ–≤–∏–∫': ['–±–æ–µ–≤–∏–∫', '—ç–∫—à–Ω', 'action'],
                '–∫–æ–º–µ–¥–∏—è': ['–∫–æ–º–µ–¥–∏—è', 'comedy'],
                '–¥—Ä–∞–º–∞': ['–¥—Ä–∞–º–∞', 'drama'],
                '—É–∂–∞—Å—ã': ['—É–∂–∞—Å—ã', '—Ö–æ—Ä—Ä–æ—Ä', 'horror'],
                '—Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞': ['—Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞', 'sci-fi', '–Ω–∞—É—á–Ω–∞—è —Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞'],
                '—Ç—Ä–∏–ª–ª–µ—Ä': ['—Ç—Ä–∏–ª–ª–µ—Ä', 'thriller'],
                '–º–µ–ª–æ–¥—Ä–∞–º–∞': ['–º–µ–ª–æ–¥—Ä–∞–º–∞', '—Ä–æ–º–∞–Ω—Ç–∏–∫–∞', 'romance'],
                '–¥–µ—Ç–µ–∫—Ç–∏–≤': ['–¥–µ—Ç–µ–∫—Ç–∏–≤', 'mystery'],
                '–∞–Ω–∏–º–∞—Ü–∏—è': ['–∞–Ω–∏–º–∞—Ü–∏—è', '–º—É–ª—å—Ç—Ñ–∏–ª—å–º', 'animation'],
                '–¥–æ–∫—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π': ['–¥–æ–∫—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π', 'documentary']
            }
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–∂–∏–¥–∞–µ–º—ã–µ –∂–∞–Ω—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞
            expected_genres = []
            found_keywords = []
            
            for keyword, genre_list in genre_keywords.items():
                if keyword in query_lower:
                    expected_genres.extend(genre_list)
                    found_keywords.append(keyword)
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –∂–µ–Ω—Å–∫–∏—Ö —Ä–æ–ª–µ–π
            if any(word in query_lower for word in ['–∂–µ–Ω—â–∏–Ω', '–∂–µ–Ω—Å–∫–æ–π', '–≥–µ—Ä–æ–∏–Ω—è', '–¥–µ–≤—É—à–∫']):
                # –ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç —Ñ–∏–ª—å–º —Å –∂–µ–Ω—â–∏–Ω–æ–π –≤ –≥–ª–∞–≤–Ω–æ–π —Ä–æ–ª–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
                if not any(word in overview for word in ['–∂–µ–Ω—â–∏–Ω', '–¥–µ–≤—É—à–∫', '–≥–µ—Ä–æ–∏–Ω—è', 'woman', 'female', 'girl']):
                    logger.info(f"Movie doesn't seem to have female protagonist despite request")
                    
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∂–∞–Ω—Ä–æ–≤ (–∏—Å–∫–ª—é—á–µ–Ω–∏—è)
            comedy_romance_indicators = ['–º–µ–ª–æ–¥—Ä–∞–º–∞', '–∫–æ–º–µ–¥–∏—è', '—Ä–æ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π', '—Ä–æ–º–∞–Ω—Ç–∏–∫–∞']
            if any(word in query_lower for word in ['–±–æ–µ–≤–∏–∫', '—ç–∫—à–Ω', 'action']):
                # –ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç –±–æ–µ–≤–∏–∫, –Ω–æ –Ω–∞—à–ª–∏ –º–µ–ª–æ–¥—Ä–∞–º—É/–∫–æ–º–µ–¥–∏—é
                if any(genre in genres for genre in comedy_romance_indicators):
                    logger.info(f"Requested action but found romance/comedy: {genres}")
                    return False
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –æ–∂–∏–¥–∞–µ–º—ã–µ –∂–∞–Ω—Ä—ã, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
            if expected_genres:
                has_matching_genre = any(genre in genres for genre in expected_genres)
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –±–æ–µ–≤–∏–∫–æ–≤
                if '–±–æ–µ–≤–∏–∫' in found_keywords:
                    action_genres = ['–±–æ–µ–≤–∏–∫', '—ç–∫—à–Ω', '—Ç—Ä–∏–ª–ª–µ—Ä', '–∫—Ä–∏–º–∏–Ω–∞–ª', '–ø—Ä–∏–∫–ª—é—á–µ–Ω–∏—è']
                    has_action = any(genre in genres for genre in action_genres)
                    
                    # –ï—Å–ª–∏ —ç—Ç–æ —è–≤–Ω–æ –ù–ï –±–æ–µ–≤–∏–∫ (–º–µ–ª–æ–¥—Ä–∞–º–∞, –∫–æ–º–µ–¥–∏—è –±–µ–∑ —ç–∫—à–µ–Ω–∞)
                    non_action_genres = ['–º–µ–ª–æ–¥—Ä–∞–º–∞', '–∫–æ–º–µ–¥–∏—è', '–¥–æ–∫—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π']
                    is_non_action = any(genre in genres for genre in non_action_genres)
                    
                    if is_non_action and not has_action:
                        logger.info(f"Requested action but found non-action genres: {genres}")
                        return False
                
                logger.info(f"Fallback validation: Expected {expected_genres}, Found {genres}, Match: {has_matching_genre}")
                return has_matching_genre
            
            # –ï—Å–ª–∏ –Ω–µ —Å–º–æ–≥–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∂–∞–Ω—Ä –∏–∑ –∑–∞–ø—Ä–æ—Å–∞, –¥–µ–ª–∞–µ–º –±–∞–∑–æ–≤—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ —è–≤–Ω–æ –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ–∏–ª—å–º
            non_matching_patterns = [
                ('–±–æ–µ–≤–∏–∫', ['–º–µ–ª–æ–¥—Ä–∞–º–∞', '–∫–æ–º–µ–¥–∏—è', '–¥–æ–∫—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π']),
                ('—É–∂–∞—Å—ã', ['–∫–æ–º–µ–¥–∏—è', '–º–µ–ª–æ–¥—Ä–∞–º–∞', '–¥–µ—Ç—Å–∫–∏–π']),
                ('–∫–æ–º–µ–¥–∏—è', ['—É–∂–∞—Å—ã', '—Ç—Ä–∏–ª–ª–µ—Ä', '–¥—Ä–∞–º–∞']),
                ('–¥–µ—Ç—Å–∫', ['—É–∂–∞—Å—ã', '—Ç—Ä–∏–ª–ª–µ—Ä', '–≤–∑—Ä–æ—Å–ª—ã–π'])
            ]
            
            for request_pattern, incompatible_genres in non_matching_patterns:
                if request_pattern in query_lower:
                    if any(genre in genres for genre in incompatible_genres):
                        logger.info(f"Incompatible genres found for '{request_pattern}': {genres}")
                        return False
            
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–∞–∑—Ä–µ—à–∞–µ–º, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —è–≤–Ω—ã—Ö –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π
            return True
            
        except Exception as e:
            logger.error(f"Fallback validation error: {e}")
            return True

    async def _search_person_in_tmdb(self, person_name: str) -> Optional[Dict[str, Any]]:
        """
        Search for a person (actor/director) in TMDB.
        
        Args:
            person_name: Name of the person to search for
            
        Returns:
            Person information from TMDB or None if not found
        """
        try:
            async with httpx.AsyncClient(timeout=15.0, verify=True) as client:
                search_url = f"{self.tmdb_base_url}/search/person"
                params = {
                    "api_key": self.tmdb_api_key,
                    "query": person_name,
                    "language": "ru-RU"
                }
                
                response = await client.get(search_url, params=params)
                response.raise_for_status()
                search_results = response.json()
                
                if search_results.get('results'):
                    person = search_results['results'][0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    
                    # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–µ–ª–æ–≤–µ–∫–µ
                    person_id = person['id']
                    details_url = f"{self.tmdb_base_url}/person/{person_id}"
                    params = {
                        "api_key": self.tmdb_api_key,
                        "language": "ru-RU",
                        "append_to_response": "movie_credits"
                    }
                    
                    response = await client.get(details_url, params=params)
                    response.raise_for_status()
                    person_details = response.json()
                    
                    return person_details
                    
                return None
                
        except Exception as e:
            logger.error(f"Error searching person in TMDB: {e}")
            return None

    async def _get_movies_by_genre(self, genre_name: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Get popular movies by genre from TMDB.
        
        Args:
            genre_name: Genre name in Russian or English
            limit: Maximum number of movies to return
            
        Returns:
            List of movies in the specified genre
        """
        try:
            # –ú–∞–ø–ø–∏–Ω–≥ –∂–∞–Ω—Ä–æ–≤ –Ω–∞ TMDB ID
            genre_mapping = {
                '–±–æ–µ–≤–∏–∫': 28, 'action': 28,
                '–ø—Ä–∏–∫–ª—é—á–µ–Ω–∏—è': 12, 'adventure': 12,
                '–∞–Ω–∏–º–∞—Ü–∏—è': 16, 'animation': 16,
                '–∫–æ–º–µ–¥–∏—è': 35, 'comedy': 35,
                '–∫—Ä–∏–º–∏–Ω–∞–ª': 80, 'crime': 80,
                '–¥–æ–∫—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π': 99, 'documentary': 99,
                '–¥—Ä–∞–º–∞': 18, 'drama': 18,
                '—Å–µ–º–µ–π–Ω—ã–π': 10751, 'family': 10751,
                '—Ñ—ç–Ω—Ç–µ–∑–∏': 14, 'fantasy': 14,
                '–∏—Å—Ç–æ—Ä–∏—è': 36, 'history': 36,
                '—É–∂–∞—Å—ã': 27, 'horror': 27,
                '–º—É–∑—ã–∫–∞': 10402, 'music': 10402,
                '–¥–µ—Ç–µ–∫—Ç–∏–≤': 9648, 'mystery': 9648,
                '–º–µ–ª–æ–¥—Ä–∞–º–∞': 10749, 'romance': 10749,
                '—Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞': 878, 'science fiction': 878, 'sci-fi': 878,
                '—Ç—Ä–∏–ª–ª–µ—Ä': 53, 'thriller': 53,
                '–≤–æ–µ–Ω–Ω—ã–π': 10752, 'war': 10752,
                '–≤–µ—Å—Ç–µ—Ä–Ω': 37, 'western': 37
            }
            
            genre_id = genre_mapping.get(genre_name.lower())
            if not genre_id:
                logger.warning(f"Genre '{genre_name}' not found in mapping")
                return []
            
            async with httpx.AsyncClient(timeout=15.0, verify=True) as client:
                discover_url = f"{self.tmdb_base_url}/discover/movie"
                params = {
                    "api_key": self.tmdb_api_key,
                    "with_genres": genre_id,
                    "language": "ru-RU",
                    "sort_by": "popularity.desc",
                    "page": 1
                }
                
                response = await client.get(discover_url, params=params)
                response.raise_for_status()
                results = response.json()
                
                movies = []
                for movie in results.get('results', [])[:limit]:
                    movie_info = {
                        'title': movie.get('title', ''),
                        'original_title': movie.get('original_title', ''),
                        'release_date': movie.get('release_date', ''),
                        'overview': movie.get('overview', ''),
                        'vote_average': movie.get('vote_average', 0),
                        'tmdb_id': movie.get('id')
                    }
                    movies.append(movie_info)
                
                return movies
                
        except Exception as e:
            logger.error(f"Error getting movies by genre: {e}")
            return []

    async def _get_person_filmography(self, person_name: str, role: str = 'cast') -> List[Dict[str, Any]]:
        """
        Get filmography of a person (actor or director).
        
        Args:
            person_name: Name of the person
            role: 'cast' for actor, 'crew' for director
            
        Returns:
            List of movies the person participated in
        """
        try:
            person_details = await self._search_person_in_tmdb(person_name)
            if not person_details:
                return []
            
            movie_credits = person_details.get('movie_credits', {})
            
            if role == 'cast':
                credits = movie_credits.get('cast', [])
            else:  # crew
                credits = movie_credits.get('crew', [])
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∂–∏—Å—Å–µ—Ä–æ–≤
                credits = [c for c in credits if c.get('job') == 'Director']
            
            movies = []
            for credit in credits[:15]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 15 —Ñ–∏–ª—å–º–æ–≤
                movie_info = {
                    'title': credit.get('title', ''),
                    'original_title': credit.get('original_title', ''),
                    'release_date': credit.get('release_date', ''),
                    'character': credit.get('character', '') if role == 'cast' else '',
                    'job': credit.get('job', '') if role == 'crew' else '',
                    'vote_average': credit.get('vote_average', 0),
                    'tmdb_id': credit.get('id')
                }
                movies.append(movie_info)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏/—Ä–µ–π—Ç–∏–Ω–≥—É
            movies.sort(key=lambda x: x['vote_average'], reverse=True)
            return movies[:10]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-10
            
        except Exception as e:
            logger.error(f"Error getting person filmography: {e}")
            return []

    async def _enrich_query_with_tmdb_data(self, user_query: str) -> str:
        """
        Enrich user query with real data from TMDB API.
        
        Args:
            user_query: Original user query
            
        Returns:
            Enhanced query with real TMDB data
        """
        try:
            enhanced_query = user_query
            query_lower = user_query.lower()
            
            # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∏–ª—å–º–æ–≤ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤—ã—à–µ –ø–µ—Ä—Å–æ–Ω)
            movie_patterns = [
                r'"([^"]+)"',  # —Ñ–∏–ª—å–º—ã –≤ –∫–∞–≤—ã—á–∫–∞—Ö
                r'–∫–∞–∫\s+([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)*)',  # "–∫–∞–∫ –ò–Ω—Ç–µ—Ä—Å—Ç–µ–ª–ª–∞—Ä", "–∫–∞–∫ –î–∂–æ–Ω –£–∏–∫"
                r'—Ç–∏–ø–∞\s+([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)*)',  # "—Ç–∏–ø–∞ –ú–∞—Ç—Ä–∏—Ü—ã", "—Ç–∏–ø–∞ –î–∂–æ–Ω –£–∏–∫"  
                r'–ø–æ—Ö–æ–∂[–∞-—è]*\s+–Ω–∞\s+([–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)*)',  # "–ø–æ—Ö–æ–∂–∏–µ –Ω–∞ –î–∂–æ–Ω –£–∏–∫"
            ]
            
            found_movies = set()
            for pattern in movie_patterns:
                matches = re.findall(pattern, user_query)
                for match in matches:
                    movie_title = match.strip()
                    # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–ª–∏ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
                    if len(movie_title) > 2 and movie_title not in ['–í—Å–µ', '–ß—Ç–æ', '–ö–∞–∫', '–ì–¥–µ', '–≠—Ç–æ', '–¢–∞–º']:
                        found_movies.add(movie_title)
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∏–ª—å–º–∞—Ö
            for movie_title in list(found_movies)[:2]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 2 —Ñ–∏–ª—å–º–æ–≤
                logger.info(f"Searching TMDB data for movie: {movie_title}")
                movie_details = await self._get_movie_details_from_tmdb(movie_title)
                if movie_details:
                    genres_str = ", ".join(movie_details.get('genres', []))
                    directors_str = ", ".join(movie_details.get('directors', []))
                    enhanced_query += f"\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ TMDB –æ —Ñ–∏–ª—å–º–µ \"{movie_details['title']}\": –∂–∞–Ω—Ä—ã - {genres_str}, —Ä–µ–∂–∏—Å—Å–µ—Ä - {directors_str}, —Ä–µ–π—Ç–∏–Ω–≥ - {movie_details.get('vote_average', 'N/A')}/10"

            # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∞–∫—Ç–µ—Ä–æ–≤/—Ä–µ–∂–∏—Å—Å–µ—Ä–æ–≤ (–∏—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å–º—ã)
            person_patterns = [
                r'—Å\s+([–ê-–Ø–Å][–∞-—è—ë]+[—ã–æ–∞—É–µ–π–º—Ö]?\s+[–ê-–Ø–Å][–∞-—è—ë]+[—ã–æ–∞—É–µ–π–º—Ö]?)',  # "—Å –¢–æ–º–æ–º –•—ç–Ω–∫—Å–æ–º" 
                r'–æ—Ç\s+(?:—Ä–µ–∂–∏—Å—Å–µ—Ä–∞\s+)?([–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?\s+[–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?)',  # "–æ—Ç –°—Ç–∏–≤–µ–Ω–∞ –°–ø–∏–ª–±–µ—Ä–≥–∞"
                r'–∞–∫—Ç–µ—Ä[–∞-—è]*\s+([–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?\s+[–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?)',  # "–∞–∫—Ç–µ—Ä–∞ –†–æ–±–µ—Ä—Ç–∞ –î–∞—É–Ω–∏"
                r'—Ä–µ–∂–∏—Å—Å–µ—Ä[–∞-—è]*\s+([–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?\s+[–ê-–Ø–Å][–∞-—è—ë]+[–∞—É—ã]?)',  # "—Ä–µ–∂–∏—Å—Å–µ—Ä–∞ –ö—Ä–∏—Å—Ç–æ—Ñ–µ—Ä–∞ –ù–æ–ª–∞–Ω–∞"
            ]
            
            found_persons = set()
            for pattern in person_patterns:
                matches = re.findall(pattern, user_query)
                for match in matches:
                    if len(match.split()) == 2:  # –ò–º—è –∏ —Ñ–∞–º–∏–ª–∏—è
                        person_name = match.strip()
                        # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∏–ª—å–º–æ–≤
                        if person_name not in found_movies:
                            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø–∞–¥–µ–∂–∏ –≤ –∏–º–µ–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂ (–±–∞–∑–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)
                            normalized_name = self._normalize_person_name(person_name)
                            found_persons.add(normalized_name)
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞—Ö
            for person_name in list(found_persons)[:2]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 2 –ø–µ—Ä—Å–æ–Ω
                logger.info(f"Searching TMDB data for person: {person_name}")
                
                # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–ª—å–º–æ–≥—Ä–∞—Ñ–∏—é –∫–∞–∫ –∞–∫—Ç–µ—Ä–∞
                actor_movies = await self._get_person_filmography(person_name, 'cast')
                if actor_movies:
                    movies_list = ", ".join([f'"{m["title"]}" ({m["release_date"][:4] if m["release_date"] else "N/A"})' 
                                           for m in actor_movies[:5]])
                    enhanced_query += f"\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ TMDB - {person_name} –∫–∞–∫ –∞–∫—Ç–µ—Ä —Å–Ω–∏–º–∞–ª—Å—è –≤: {movies_list}"
                
                # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–ª—å–º–æ–≥—Ä–∞—Ñ–∏—é –∫–∞–∫ —Ä–µ–∂–∏—Å—Å–µ—Ä–∞
                director_movies = await self._get_person_filmography(person_name, 'crew')
                if director_movies:
                    movies_list = ", ".join([f'"{m["title"]}" ({m["release_date"][:4] if m["release_date"] else "N/A"})' 
                                           for m in director_movies[:5]])
                    enhanced_query += f"\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ TMDB - {person_name} –∫–∞–∫ —Ä–µ–∂–∏—Å—Å–µ—Ä —Å–Ω—è–ª: {movies_list}"
            
            # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∂–∞–Ω—Ä–æ–≤ –∏ –ø–æ–ª—É—á–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ñ–∏–ª—å–º—ã
            genre_keywords = {
                '–±–æ–µ–≤–∏–∫': ['–±–æ–µ–≤–∏–∫', '–±–æ–µ–≤–∏–∫–∏', '—ç–∫—à–Ω', 'action'],
                '–∫–æ–º–µ–¥–∏—è': ['–∫–æ–º–µ–¥–∏—è', '–∫–æ–º–µ–¥–∏–∏', 'comedy'],
                '–¥—Ä–∞–º–∞': ['–¥—Ä–∞–º–∞', '–¥—Ä–∞–º—ã', 'drama'],
                '—É–∂–∞—Å—ã': ['—É–∂–∞—Å—ã', '—É–∂–∞—Å', '—Ö–æ—Ä—Ä–æ—Ä', 'horror'],
                '—Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞': ['—Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞', '—Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫—É', 'sci-fi', '–Ω–∞—É—á–Ω–∞—è —Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞'],
                '—Ç—Ä–∏–ª–ª–µ—Ä': ['—Ç—Ä–∏–ª–ª–µ—Ä', '—Ç—Ä–∏–ª–ª–µ—Ä—ã', 'thriller'],
                '–º–µ–ª–æ–¥—Ä–∞–º–∞': ['–º–µ–ª–æ–¥—Ä–∞–º–∞', '–º–µ–ª–æ–¥—Ä–∞–º—ã', '—Ä–æ–º–∞–Ω—Ç–∏–∫–∞', '—Ä–æ–º–∞–Ω—Ç–∏–∫—É', 'romance'],
                '–¥–µ—Ç–µ–∫—Ç–∏–≤': ['–¥–µ—Ç–µ–∫—Ç–∏–≤', '–¥–µ—Ç–µ–∫—Ç–∏–≤—ã', 'mystery'],
                '–∞–Ω–∏–º–∞—Ü–∏—è': ['–∞–Ω–∏–º–∞—Ü–∏—è', '–∞–Ω–∏–º–∞—Ü–∏–æ–Ω–Ω—ã–π', '–º—É–ª—å—Ç—Ñ–∏–ª—å–º', '–º—É–ª—å—Ç—Ñ–∏–ª—å–º—ã', 'animation'],
                '–¥–æ–∫—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π': ['–¥–æ–∫—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π', '–¥–æ–∫—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ', 'documentary']
            }
            
            found_genres = []
            for genre, keywords in genre_keywords.items():
                if any(keyword in query_lower for keyword in keywords):
                    found_genres.append(genre)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ñ–∏–ª—å–º—ã –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∂–∞–Ω—Ä–æ–≤
            for genre in found_genres[:2]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 2 –∂–∞–Ω—Ä–æ–≤
                logger.info(f"Getting popular movies for genre: {genre}")
                popular_movies = await self._get_movies_by_genre(genre, 5)
                if popular_movies:
                    movies_list = ", ".join([f'"{m["title"]}" ({m["release_date"][:4] if m["release_date"] else "N/A"}, —Ä–µ–π—Ç–∏–Ω–≥ {m["vote_average"]}/10)' 
                                           for m in popular_movies])
                    enhanced_query += f"\n\n–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ {genre}—ã –∏–∑ TMDB: {movies_list}"
            
            if enhanced_query != user_query:
                logger.info("Query enhanced with TMDB data")
                return enhanced_query
            else:
                logger.info("No additional TMDB data found for query")
                return user_query
                
        except Exception as e:
            logger.error(f"Error enriching query with TMDB data: {e}")
            return user_query

    def _normalize_person_name(self, name: str) -> str:
        """
        Normalize person name from different Russian cases to nominative case.
        
        Args:
            name: Person name in any case
            
        Returns:
            Normalized name in nominative case
        """
        try:
            # –ë–∞–∑–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä—É—Å—Å–∫–∏—Ö –∏–º–µ–Ω –∏ —Ñ–∞–º–∏–ª–∏–π
            name_mapping = {
                # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∞–∫—Ç–µ—Ä—ã (–∏–∑ –∫–æ—Å–≤–µ–Ω–Ω—ã—Ö –ø–∞–¥–µ–∂–µ–π –≤ –∏–º–µ–Ω–∏—Ç–µ–ª—å–Ω—ã–π)
                '—Ç–æ–º–æ–º —Ö—ç–Ω–∫—Å–æ–º': '–¢–æ–º –•—ç–Ω–∫—Å',
                '—Ç–æ–º–∞ —Ö—ç–Ω–∫—Å–∞': '–¢–æ–º –•—ç–Ω–∫—Å',
                '—Å—Ç–∏–≤–µ–Ω–∞ —Å–ø–∏–ª–±–µ—Ä–≥–∞': '–°—Ç–∏–≤–µ–Ω –°–ø–∏–ª–±–µ—Ä–≥',
                '—Å—Ç–∏–≤–µ–Ω–æ–º —Å–ø–∏–ª–±–µ—Ä–≥–æ–º': '–°—Ç–∏–≤–µ–Ω –°–ø–∏–ª–±–µ—Ä–≥',
                '—Ä–æ–±–µ—Ä—Ç–∞ –¥–∞—É–Ω–∏': '–†–æ–±–µ—Ä—Ç –î–∞—É–Ω–∏',
                '—Ä–æ–±–µ—Ä—Ç–æ–º –¥–∞—É–Ω–∏': '–†–æ–±–µ—Ä—Ç –î–∞—É–Ω–∏',
                '–∫—Ä–∏—Å—Ç–æ—Ñ–µ—Ä–∞ –Ω–æ–ª–∞–Ω–∞': '–ö—Ä–∏—Å—Ç–æ—Ñ–µ—Ä –ù–æ–ª–∞–Ω',
                '–∫—Ä–∏—Å—Ç–æ—Ñ–µ—Ä–æ–º –Ω–æ–ª–∞–Ω–æ–º': '–ö—Ä–∏—Å—Ç–æ—Ñ–µ—Ä –ù–æ–ª–∞–Ω',
                '–ª–µ–æ–Ω–∞—Ä–¥–æ –¥–∏–∫–∞–ø—Ä–∏–æ': '–õ–µ–æ–Ω–∞—Ä–¥–æ –î–∏–ö–∞–ø—Ä–∏–æ',
                '–ª–µ–æ–Ω–∞—Ä–¥–æ–º –¥–∏–∫–∞–ø—Ä–∏–æ': '–õ–µ–æ–Ω–∞—Ä–¥–æ –î–∏–ö–∞–ø—Ä–∏–æ',
                '–±—Ä—ç–¥–∞ –ø–∏—Ç—Ç–∞': '–ë—Ä—ç–¥ –ü–∏—Ç—Ç',
                '–±—Ä—ç–¥–æ–º –ø–∏—Ç—Ç–æ–º': '–ë—Ä—ç–¥ –ü–∏—Ç—Ç',
                '–¥–∂–æ–Ω–Ω–∏ –¥–µ–ø–ø–∞': '–î–∂–æ–Ω–Ω–∏ –î–µ–ø–ø',
                '–¥–∂–æ–Ω–Ω–∏ –¥–µ–ø–ø–æ–º': '–î–∂–æ–Ω–Ω–∏ –î–µ–ø–ø',
                '—É–∏–ª–ª–∞ —Å–º–∏—Ç–∞': '–£–∏–ª–ª –°–º–∏—Ç',
                '—É–∏–ª–ª–æ–º —Å–º–∏—Ç–æ–º': '–£–∏–ª–ª –°–º–∏—Ç',
                '–∫–≤–µ–Ω—Ç–∏–Ω–∞ —Ç–∞—Ä–∞–Ω—Ç–∏–Ω–æ': '–ö–≤–µ–Ω—Ç–∏–Ω –¢–∞—Ä–∞–Ω—Ç–∏–Ω–æ',
                '–∫–≤–µ–Ω—Ç–∏–Ω–æ–º —Ç–∞—Ä–∞–Ω—Ç–∏–Ω–æ': '–ö–≤–µ–Ω—Ç–∏–Ω –¢–∞—Ä–∞–Ω—Ç–∏–Ω–æ',
                '–º–∞—Ä—Ç–∏–Ω–∞ —Å–∫–æ—Ä—Å–µ–∑–µ': '–ú–∞—Ä—Ç–∏–Ω –°–∫–æ—Ä—Å–µ–∑–µ',
                '–º–∞—Ä—Ç–∏–Ω–æ–º —Å–∫–æ—Ä—Å–µ–∑–µ': '–ú–∞—Ä—Ç–∏–Ω –°–∫–æ—Ä—Å–µ–∑–µ',
                '—Å–∫–∞—Ä–ª–µ—Ç—Ç –π–æ—Ö–∞–Ω—Å—Å–æ–Ω': '–°–∫–∞—Ä–ª–µ—Ç—Ç –ô–æ—Ö–∞–Ω—Å—Å–æ–Ω',
                '—Å–∫–∞—Ä–ª–µ—Ç—Ç –π–æ—Ö–∞–Ω—Å—Å–æ–Ω': '–°–∫–∞—Ä–ª–µ—Ç—Ç –ô–æ—Ö–∞–Ω—Å—Å–æ–Ω',
                '–∞–Ω–¥–∂–µ–ª–∏–Ω—ã –¥–∂–æ–ª–∏': '–ê–Ω–¥–∂–µ–ª–∏–Ω–∞ –î–∂–æ–ª–∏',
                '–∞–Ω–¥–∂–µ–ª–∏–Ω–æ–π –¥–∂–æ–ª–∏': '–ê–Ω–¥–∂–µ–ª–∏–Ω–∞ –î–∂–æ–ª–∏',
            }
            
            name_lower = name.lower().strip()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä—è–º–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
            if name_lower in name_mapping:
                return name_mapping[name_lower]
            
            # –ë–∞–∑–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–∫–æ–Ω—á–∞–Ω–∏–π –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∏–º–µ–Ω
            words = name.split()
            if len(words) == 2:
                first_name, last_name = words
                
                # –£–±–∏—Ä–∞–µ–º —Ç–∏–ø–∏—á–Ω—ã–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è –∫–æ—Å–≤–µ–Ω–Ω—ã—Ö –ø–∞–¥–µ–∂–µ–π
                # –ò–º–µ–Ω–∞
                if first_name.lower().endswith(('–æ–º', '–µ–º', '—ã–º', '—ã–º')):
                    first_name = first_name[:-2]
                elif first_name.lower().endswith(('–∞', '—è', '—É', '—é', '—ã', '–∏', '–µ')):
                    if len(first_name) > 3:  # –ò–∑–±–µ–≥–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏—Ö –∏–º–µ–Ω
                        first_name = first_name[:-1]
                
                # –§–∞–º–∏–ª–∏–∏
                if last_name.lower().endswith(('–æ–º', '–µ–º', '—ã–º', '–∏–º')):
                    last_name = last_name[:-2]
                elif last_name.lower().endswith(('–∞', '—è', '—É', '—é', '—ã', '–∏', '–µ')):
                    if len(last_name) > 4:  # –§–∞–º–∏–ª–∏–∏ –æ–±—ã—á–Ω–æ –¥–ª–∏–Ω–Ω–µ–µ
                        last_name = last_name[:-1]
                
                return f"{first_name.title()} {last_name.title()}"
            
            return name.title()
            
        except Exception as e:
            logger.error(f"Error normalizing person name: {e}")
            return name.title() 